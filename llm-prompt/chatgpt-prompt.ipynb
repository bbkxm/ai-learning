{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e52449d6-48ed-4c31-bead-4e3050902cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = 'sk-888'\n",
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbeea16a-0a55-4ee4-a98b-ecd0693a1e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\":\"user\",\"content\":prompt}]\n",
    "    response = client.chat.completions.create(  \n",
    "      model=model,\n",
    "      messages=messages,\n",
    "      temperature=0.8,\n",
    "      max_tokens=60\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a81e093-f09a-4b7c-9061-bb7ca0e2441f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clear and specific instructions should be provided to guide a model towards the desired output and reduce the chances of receiving irrelevant or incorrect responses, with longer prompts often providing more clarity and context for more detailed and relevant outputs.\n"
     ]
    }
   ],
   "source": [
    "text=f\"\"\"\n",
    "You should express what you want a model to do by  providing instructions that are as clear and specific as you can possibly make them.\n",
    "This will guide the model towards the desired output,and reduce the chances of receiving irrelevant\n",
    "or incorrect responses.Don't confuse writing a clear prompt with writing a short prompt.\n",
    "In many cases,longer prompts provide more clarity\\ and context for the model, which can lead to more detailed and relevant outputs.\n",
    "\"\"\"\n",
    "prompt=f\"\"\"\n",
    "Summarize the text delimited by triple backticks into a single sentence.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add41bcd-3fec-4eb8-a017-646914df2a24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
